\subsection{Result using Gradient Boosted Trees}

The gradient boosted trees algorithm is used to create an ensemble of decision trees trough gradually improved estimations. The output is a classification model which can be applied to the test dataset for a prediction of the label attribute position\_grouped. \newline
One advantage is the written report about the weights of attributes with respect to the label attribute.~\cite{ref_rapidminergbt}
The number of trees was set to 30. The maximal depth was initially set to 15, while the best result was scored with a maximal depth of 30.
The number of bins was set to 30.  
The process using cross-validation was executed different maximal depth of trees (10, 15, 25 and 30). With less than one percent deviation a recall of 88,21 \% and a precision of 89,01 \% was scored during the four different runs. The mean squared  errors was between 0.32 and 0.33. The best result was scored having a maximal tree depth of 10.


As important attributes the following were highlighted in table \ref{Tab:GBTImportantAttributes}:

\begin{table}[]
\begin{tabular}{@{}llll@{}}
\toprule
Variable        & \begin{tabular}[c]{@{}l@{}}Relative \\ Importance\end{tabular} & \begin{tabular}[c]{@{}l@{}}Scales \\ Importance\end{tabular}    & Percentage \\ \midrule
SlidingTackle   & 43887.371094        & 1.000000 & 0.179607   \\
Skill Moves     & 40664.996094        & 0.926576                      & 0.166419   \\
LongPassing     & 27751.718750        & 0.632340                      & 0.113572   \\
LCB             & 23368.140625        & 0.532457                      & 0.095633   \\
HeadingAccuracy & 22303.111328        & 0.508190                      & 0.091274   \\
LAM             & 16302.590820        & 0.371464                      & 0.066717   \\
Finishing       & 9715.319336         & 0.221369                      & 0.039759   \\
Crossing        & 9004.551758         & 0.205174                      & 0.036851   \\
SprintSpeed     & 5180.378906         & 0.118038                      & 0.021200   \\
ShortPassing    & 3899.299316         & 0.088848                      & 0.015958   \\ \bottomrule
\end{tabular}
\label{Tab:GBTImportantAttributes}
\caption{Important Attributes according to Gradient Boosted Trees algorithm}
\end{table}

The following table \ref{Tab:ResultOptimizeSelectionGBT} presents the result of the optimize selection operator. Noteworthy are the worst results for predicting a striker, while all goalkeepers were classified correctly. The accuracy is 87,7 \%, weighted recall is 88,58 \% and the weighted precision is 87,10 \%.

\begin{table}[]
\begin{tabular}{@{}l|lllll@{}}
\toprule
                 & True Defender & True Goalkeeper & True Midfielder & \multicolumn{1}{l|}{True Strikers} & Class precision \\ \midrule
Pred. Defender   & 5431          & 0               & 475             & \multicolumn{1}{l|}{22}            & 91,62 \%        \\
Pred. Goalkeeper & 0             & 2025            & 0               & \multicolumn{1}{l|}{0}             & 100 \%          \\
Pred. Midfielder & 431           & 0               & 5859            & \multicolumn{1}{l|}{769}           & 82,68 \%        \\
Pred. Strikers   & 4             & 0               & 504             & \multicolumn{1}{l|}{2600}          & 83,66 \%        \\ \midrule
Class recall     & 92,58\%       & 100 \%          & 85,68 \%        & 76,07 \%                           &                 \\ \bottomrule
\end{tabular}
\label{Tab:ResultOptimizeSelectionGBT}
\caption{Confusion Matrix for Gradient Boosted Trees algorithm}
\end{table}

