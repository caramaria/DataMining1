\subsection{Gradient Boosted Trees}
After using KNN we continued with algorithms which are using decision trees. First we uses a classical decision tree but the results could not compete with KNN, therefore we started to apply more advanced algorithm such as the Gradient Boosted Trees (GBT).\\
The GBT algorithm is used to create an ensemble of decision trees trough gradually improved estimations. The output is a classification model which can be applied to the test data set for a prediction of the label attribute\textit{ position\_grouped}. Using GBT provides the advantage that a written report about the weights of the attributes with respect to the label attribute is created~\cite{ref_rapidminergbt}. The algorithm builds variuos trees which are focusing to include attributes with higher weights than before. The trees are build on variations of the original dataset. Classification errors from previous trees are taken into account before building a new tree ~\cite{ref_towardsGBT}.\\
To run the algorithm an ``optimize selection'' operator was applied to test the best combination of maximal tree depth and number of trees.  The highest accuracy result was scored building 32 different trees. The maximal depth had no influence according to the operator testing with a step size of 3, since a accuracy of 87 \% was achieved regardless of the tree depth of 10 or 25.\\
The GBT logs the most important variables to build the model. The identified attributes were HeadingAccuracy (percentage 0.21 \%), SlidingTackle (0.19 \%), Vision (0.17 \%) and Finishing(0.1 \%).\\
The confusion matrix in table 6 presents the test results. Noteworthy are the bad results for predicting a striker, while all goalkeepers were classified correctly. The overall accuracy was 87.02 \%. Weighted recall is 88.15 \% and weighted precision is 88.88 \%. \\
\begin{table}[h]
\centering
\begin{tabular}{l|lllll}
\hline
                 & True Strikers & \begin{tabular}[c]{@{}l@{}}True \\ Goalkeeper\end{tabular} & True Midfielder & \multicolumn{1}{l|}{True Defender} & \begin{tabular}[c]{@{}l@{}}Class \\ precision\end{tabular} \\ \hline
Pred. Strikers   & 881           & 0                                                          & 245             & \multicolumn{1}{l|}{4}             & 77,96 \%                                                   \\
Pred. Goalkeeper & 0             & 629                                                        & 0               & \multicolumn{1}{l|}{1}             & 99,84 \%                                                   \\
Pred. Midfielder & 245           & 2                                                          & 2183            & \multicolumn{1}{l|}{172}           & 83,9 \%                                                    \\
Pred. Defender   & 5             & 1                                                          & 224             & \multicolumn{1}{l|}{2357}          & 91,11 \%                                                   \\ \hline
Class recall     & 77.9 \%       & 99.53 \%                                                   & 82.32 \%        & 93.01 \%                           &                                                            \\ \hline
\end{tabular}
\label{Tab:ResultOptimizeSelectionGBT}
\caption{Confusion Matrix for Gradient Boosted Trees algorithm}
\end{table}
Applying the learned model to the test data set an accuracy of 87.06 \% was scored. 
As before, the prediction for goalkeepers and defender worked well with a recall higher than 91 \%. For the defender class the recall value increased by 1.12 \% from 91.89 \% to 93.01 \%. However a decrease in recall by 0.47 \% was measured for the goalkeepers. Using the cross validation the difference for the strikers and the midfielder is less than 2 \% compared to the FIFA19 data set.



